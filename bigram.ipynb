{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "usage: ipykernel_launcher.py [-h] -bs BS\n",
      "ipykernel_launcher.py: error: the following arguments are required: -bs\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F \n",
    "import mmap\n",
    "import random\n",
    "import pickle \n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description = 'This is a deomnstration Program')\n",
    "parser.add_argument('-bs',type=str, required = True, help = 'Batch Size' )\n",
    "args = parser.parse_args()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'batch size:{args.batch_size}')\n",
    "print(device)\n",
    "block_size= 64 \n",
    "batch_size = args.batch_size\n",
    "learning_rate = 3e-4\n",
    "max_iters = 200\n",
    "eval_iters = 250\n",
    "dropout = 0.2\n",
    "n_embd = 384\n",
    "n_layer = 8\n",
    "n_head = 8\n",
    "dropout  = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "chars = \"\"\n",
    "with open('openwebtext/vocab.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    chars = sorted(set(text))\n",
    "\n",
    "print(chars)\n",
    "print(len(chars))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,  1, 47, 33,\n",
      "        50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26, 49,  0,  0,\n",
      "         1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,  0,  0,  1,\n",
      "         1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1, 47, 33, 50,\n",
      "        25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1, 36, 25, 38,\n",
      "        28,  1, 39, 30,  1, 39, 50,  9,  1, 39])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = { i: ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[72,  1, 62,  ..., 61, 62, 60],\n",
      "        [ 1, 58, 67,  ...,  1, 66, 62],\n",
      "        [67,  1, 54,  ..., 73,  1, 66],\n",
      "        ...,\n",
      "        [75, 62, 73,  ..., 67, 60, 72],\n",
      "        [73,  1, 66,  ..., 58,  1, 61],\n",
      "        [59,  0, 69,  ..., 60, 54, 62]])\n",
      "targrets:\n",
      "tensor([[ 1, 62, 67,  ..., 62, 60, 61],\n",
      "        [58, 67, 57,  ..., 66, 62, 57],\n",
      "        [ 1, 54, 67,  ...,  1, 66, 74],\n",
      "        ...,\n",
      "        [62, 73, 54,  ..., 60, 72,  1],\n",
      "        [ 1, 66, 58,  ...,  1, 61, 58],\n",
      "        [ 0, 69, 71,  ..., 54, 62, 67]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_random_chunk(split):\n",
    "    filename = \"openwebtext/train_split.txt\" if split == 'train' else 'openwebtext/val_split.txt'\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access= mmap.ACCESS_READ) as mm:\n",
    "\n",
    "            file_size = len(mm)\n",
    "            start_pos = random.randint(0,(file_size) - block_size*batch_size)\n",
    "\n",
    "            mm.seek(start_pos)\n",
    "            block = mm.read(block_size* batch_size-1  )\n",
    "            decoded_block = block.decode('utf-8', error= 'ignore').replace('\\r', '')\n",
    "            data = torch.tensor(encode(decoded_block), dtype = torch.long)\n",
    "    return data \n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = get_random_chunk(split)\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device) , y.to(device)\n",
    "    return x,y\n",
    "    \n",
    "x,y = get_batch('train')\n",
    "\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targrets:')\n",
    "print(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "     def __init__(self, n_embd):\n",
    "          super().__init__()\n",
    "          self.net = nn.Sequential(\n",
    "               nn.Linear(n_embd, 4 * n_embd),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(4 * n_embd, n_embd),\n",
    "               nn.Dropout(dropout),\n",
    "          )\n",
    "\n",
    "     def forward(self, x):\n",
    "          return self.net(x)\n",
    "          \n",
    "\n",
    "class Head (nn.Module):\n",
    "     def __init__(self,  head_size ):\n",
    "          super().__init__()\n",
    "          self.key = nn.Linear(n_embd, head_size, bias = False)\n",
    "          self.query = nn.Linear(n_embd, head_size, bias = False)\n",
    "          self.value = nn.Linear(n_embd, head_size, bias =False)\n",
    "          self.register_buffer('trl', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "          self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "     def forward(self, x):\n",
    "          B,T,C = x.shape\n",
    "          k = self.key(x)\n",
    "          q = self.query(x)\n",
    "          wei = q @ k.transpose(-2,-1) * k.shape[-1] ** -0.5\n",
    "          wei = wei.masked_fill(self.trl[:T, :T] == 0, float('-inf'))\n",
    "          wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "          v = self.value(x)\n",
    "          out = wei @ v\n",
    "\n",
    "          return out\n",
    "     \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads,head_size): \n",
    "          super().__init__()\n",
    "          self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "          self.proj = nn.Linear(head_size * num_heads, n_embd, bias = False)\n",
    "          self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.concat([head(x) for head in self.heads], dim =-1) #(B,T,F )---> ([h1, h1, h1, h2, h2, h2, h3, h3, h3, h4, h4, h4])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "          \n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "     def __init__(self, n_embd, n_head):\n",
    "          super().__init__()\n",
    "          head_size = n_embd // n_head\n",
    "          self.sa = MultiHeadAttention(n_head, head_size)\n",
    "          \n",
    "          self.ffwd  = FeedForward(n_embd)\n",
    "          self.ln1 = nn.LayerNorm(n_embd)\n",
    "          self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "     def forward(self, x):\n",
    "          y = self.sa(x)\n",
    "          x = self.ln1(x+y)\n",
    "          y = self.ffwd(x)\n",
    "          x = self.ln2(x+y)\n",
    "          \n",
    "          return x\n",
    "\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "       def __init__(self, vocab_size):\n",
    "           super().__init__()\n",
    "           self.token_embeddings = nn.Embedding(vocab_size, n_embd)\n",
    "           self.position_embeddings_table = nn.Embedding(block_size, n_embd)\n",
    "           self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "\n",
    "           self.ln_f = nn.LayerNorm(n_embd)\n",
    "           self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "           self.apply(self._init_weights)\n",
    "\n",
    "       def _init_weights(self, module):\n",
    "           if isinstance(module, nn.Linear):\n",
    "               torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "               if module.bias is not None:\n",
    "                   torch.nn.init.zeros_(module.bias)\n",
    "           elif isinstance(module, nn.Embedding):\n",
    "                    torch.nn.init.normal_(module.weight, mean = 0.0, std =  0.02)\n",
    "                   \n",
    "       def forward(self, index, targets=None):\n",
    "           B, T = index.shape\n",
    "           token_emb = self.token_embeddings(index)\n",
    "           pos_emb = self.position_embeddings_table(torch.arange(T, device=device))\n",
    "           x = token_emb + pos_emb\n",
    "           x = self.blocks(x)\n",
    "           x = self.ln_f(x)\n",
    "           logits = self.lm_head(x)\n",
    "\n",
    "\n",
    "           # logits has shape (B, T, C) where C == vocab_size\n",
    "           if targets is None:\n",
    "               return logits, None\n",
    "\n",
    "           B, T, C = logits.shape\n",
    "           logits = logits.view(B * T, C)\n",
    "           targets = targets.view(B * T)\n",
    "           loss = F.cross_entropy(logits, targets)\n",
    "           return logits, loss      \n",
    "\n",
    "       def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop the context to block_size if it is longer.\n",
    "            index_cond = index if index.shape[1] <= block_size else index[:, -block_size:]\n",
    "            logits, _ = self(index_cond)\n",
    "            # Focus on predictions for the last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=-1)\n",
    "        return index\n",
    "\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "743]oE3Od!&\n",
      "W2C;rL*;E4vuw[q4w5Cfaf\n",
      "]o1dFOCiPetAh[zcPP6*M.N4NW8m:jj LlzXhQRX4MOPIQEG(_CxCtLb(EO;W(fp-b:GxgQY-.Zo_3cy(7X!YQA,T.;LozlNHlp4'40\"Wo6*Cu25!qg-dBO)o1taiZkHF60]rB-\n",
      "CSYr6jcEY9i4qYD:,c?D(qWPP]';6*K3MMcELo6PPdZI?KH?*0-mrpRhq2Gih&iDrjV-B!8kDKSMlWOX0lo.:xav(rF(ojT0Dm0r?4Wv\" D5HYjNr6j-g,FoZJw84i!5s\n",
      "cYi96Zqt!.6z?VZKn XjhIR2ve-1S1RihC xnj0KECW4HGih7Ua;b)QOBj;kZD.ie:WI5-IpD?BiD,*DS)(;0N\"qQC]8Gupqskxt6ProrU?Hw92.?isqJ6qfCQ!8EobHt:HNpid;&2m(VMnO0ykl_XKUqvVwtHja0iC9iUMLpq 1p?SkmmphwHd (r ]]?*n(R4.Q\";\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "model = GPTLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "print('Loading Learnable Parameters')\n",
    "with open('model-01.pkl', 'rb') as f:\n",
    "    pickle.load(f)\n",
    "print('Model Loaded')\n",
    "m= model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.4483, val loss 4.4470\n",
      "step 250: train loss 1.6727, val loss 1.8305\n",
      "step 500: train loss 1.3159, val loss 1.6016\n",
      "step 750: train loss 1.1195, val loss 1.5587\n",
      "step 1000: train loss 0.9719, val loss 1.6050\n",
      "step 1250: train loss 0.8151, val loss 1.6972\n",
      "step 1500: train loss 0.6644, val loss 1.8327\n",
      "step 1750: train loss 0.5399, val loss 1.9876\n",
      "step 2000: train loss 0.4289, val loss 2.1893\n",
      "step 2250: train loss 0.3534, val loss 2.3530\n",
      "step 2500: train loss 0.3028, val loss 2.5364\n",
      "step 2750: train loss 0.2756, val loss 2.6397\n",
      "0.3649386763572693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n",
    "with open('model-01.pkl', 'wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wings, which they had enemied, and he pretty graw them up in jail over, and the five bird, which they\n",
      "poweced over the floor a in the floor.\n",
      "\n",
      "\"Where?\" asked the man's voice of the strange wizard, that I don't think children work,\" remarked Zeb,\n",
      "who had been until now been fore, the piggeeting of the raial of lithe unnear, and when they\n",
      "made neares and hurt being for the air and began to make the best of\n",
      "it.\n",
      "\n",
      "\"All were!\" plates the wooden with attent once gent I am\n",
      "incline.\"\n",
      "\n",
      "\"But you must remember you had the Country?\" he enquired.\n",
      "\n",
      "\"No, my granerly, and watered in hand, and her adventure, we performing strap and\n",
      "the buggy with snapped.\n",
      "\n",
      "\"Did you not wear green white fows, perhaped being one cut seems to rest, for the climb was rapider fastened\n",
      "with was covered that pedigreened very conquered.\n",
      "\n",
      "\"Now, Billina!\" she answered; \"but that is, if there is anxiousnted to have\n",
      "the boy eating his watch; and Zeb carried her with kind of the cold, the way\n",
      "and not to with the star one, noting they saw no one, can with the stame becoming\n",
      "a wize of the piglets, to have I have tried my people time, but not a great frolitted out the solid of\n",
      "people.\n",
      "\n",
      "\"And mama be that I was right important, and the Ruler's\n",
      "not as well of make her a huntil they have no blue ribbons.\"\n",
      "\n",
      "\"Does it hurt to try to somewher in the center of speech,\" remarked Zeb, with a white kick. I was a\n",
      "boy.\n",
      "\n",
      "\"To be sure,\" answered the some of the buggy and walked beside you,\n",
      "showed before it was a gloomily in the biggy soft and bite, when they\n",
      "were in no dineed to with the star of the sky.\"\n",
      "\n",
      "\"How a money will be be powerful and\" when the Prince into the Dorothy's\n",
      "of legs arms so that we can the other and there, one every one of\n",
      "the stop the floor and on the buggy caught the air like are nearly one\n",
      "with surfe.\n",
      "\n",
      "\"Our people do not pick that we all together things--if he keets\n",
      "and (ill me and of Mangaboos, and while they could man?\"\n",
      "\n",
      "\"Of course,\" replied the Wizard, \"and we have seen been by all see eyes able to\n",
      "people I will not am.\"\n",
      "\n",
      "Chich watch the first oC in the buggy saw the invisible bear th,\n",
      "and soot was quite a deal frisking a creature sign and.\n",
      "\n",
      "But the poor was reson easily as Eureka had frak.\n",
      "\n",
      "\"Don't if hurt to be invis'ble?\" she asked.\n",
      "\n",
      "\"They live in Oz your tapped the,\" replied Dorothy. \"It keep the way we to eat out\n",
      "; no one see and then upon the children and the Wizard afterward\"\n",
      "\n",
      " obeyed in a little was girl on to remore of the earth?\"\n",
      "\n",
      "\"What will happen to be a wheel of Voe?\"\n",
      "\n",
      "\"No; she it would be saved,\" remarked the only walked the straws; \"and it would be sure examine\n",
      "of the invisible bears, and a rock of could feet above the earth than the\n",
      "Garges were begining to wake up and move through the ground\n",
      "open in a way. They are in my old friends upon him and the kitten ate greed readily to\n",
      "his people and then came back to the circus, and the children and the\n",
      "Gargoyle people with this securely and he was engaping to carry the blooss and pretties that end\n",
      "the space broaders, prest that even grew them to amuse use on the ground.\"\n",
      "\n",
      "\"Why then?\" asked the woman's voice and to be the Chieveryard of the Gargoyle head, meat for some of this\n",
      "place where he was united the at piglets, sobbing that every soon could not bird it\n",
      "well for theirs and satural to be in realize this that promised to look at his watch--a big silver one furth\n",
      "every since were standing teps. They came to wher the strap was hanging he tied to the city had reached amazing themselves, in a\n",
      "whole in the breath.\n",
      "\n",
      "\"So don't want to join the gard of my balloon they made with the piglets had disappeared.\n",
      "\n",
      "\"Dear me!\" cried the Wizard, \"it is this way to join here, when\n",
      "yawning my exter. my made of which was a black was sep to another by\n",
      "grain of their disappointment that he had no becond could not crawl out of\n",
      "their dotten with the arching hard and then yawawned in the Wizard to show them, \"o' we too warnous from that we can't be live with\n",
      "them.\"\n",
      "\n",
      "\"That's the way I feel about it,\" remarked the Wizard, \"and I'm not lot leave the piglets, to make it appear that the\n",
      "obed finish was quite fishes or lived. When you ought to be carefored in the\n",
      "Black Pit in Dorothy, spreadily; \"but we cannot now be cound not recently, and one\n",
      "of the farther to him that is position the room wings, and\n",
      "Zeb pub would there was no tain to surprising a winground, and the\n",
      "ground was soon carried marched to wheels, and they are quite probably to\n",
      "off the platform and sat down quiete safe the fiel poor beJiant,\n",
      "and they made in a few moment he had entired the loook\n",
      "around the cab-horse and noting the ground into the house\n",
      "and then Zeb to watch that this realough in this Land of Oz.\"\n",
      "\n",
      "\"Now?\"\n",
      "\n",
      "\"I don't know,\" answered the boy, looking around him nine tiny piglets, sobbed Dorothy was suddenly\n",
      "about a hundre of the attendants looked roof in stoles, and when\n",
      "they came to a good without daring to scratch.\n",
      "\n",
      "\"How horrid of you, Eureka?\" cried Dorothy.\n",
      "\n",
      "\"Oh, you cannot go away?\" asked Dorothy.\n",
      "\n",
      "\"That depends upon the care we take of ou\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1) , dtype= torch.long, device = device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens = 5000)[0].tolist())\n",
    "\n",
    "\n",
    "print(generated_chars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([10], dtype = torch.float32)\n",
    "y = F.tanh(x)\n",
    "\n",
    "print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
